{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = MNIST(\"./data\", train=True, transform = transform)\n",
    "test_data = MNIST(\"./data\", train=False, transform = transform)\n",
    "trainloader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=15)\n",
    "testloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'cloudspace (Python 3.10.10)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "type(next(iter(trainloader))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fcmu = nn.Linear(256, 20)\n",
    "        self.fc2 = nn.Linear(784,256)\n",
    "        self.fcvar = nn.Linear(256,20)\n",
    "        \n",
    "        # decoder\n",
    "        self.fc3 = nn.Linear(20,256)\n",
    "        self.fc4 = nn.Linear(256,784)\n",
    "\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterization(mu, torch.exp(.5*log_var))\n",
    "        x_hat = self.decode(z)\n",
    "        x_hat\n",
    "        return x_hat\n",
    "\n",
    "    def encode(self, x):\n",
    "        x1 = self.activation(self.fc1(x))\n",
    "        mu = self.fcmu(x1)\n",
    "\n",
    "        x2 = self.activation(self.fc2(x))\n",
    "        log_var = self.fcvar(x2)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "    def decode(self,z):\n",
    "        x = self.activation(self.fc3(z))\n",
    "\n",
    "        # apply sigmoid so all values will be between (0,1)\n",
    "        # this allows for bernoulli distribution to be applied\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def reparameterization(self,mu, std):\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mu + std*epsilon\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterization(mu, torch.exp(.5*log_var))\n",
    "        x_hat = self.decode(z)\n",
    "\n",
    "        reconstruction_loss = nn.functional.binary_cross_entropy(x_hat,x, reduction=\"sum\")\n",
    "        kl_div = -0.5 * torch.sum(1+log_var - mu.pow(2)-torch.exp(log_var))\n",
    "        loss = reconstruction_loss + kl_div\n",
    "        self.log(\"training loss\",loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(accelerator=\"auto\",max_epochs=30,default_root_dir=\"checkpoints\")\n",
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | fc1        | Linear    | 200 K  | train\n",
      "1 | fcmu       | Linear    | 5.1 K  | train\n",
      "2 | fc2        | Linear    | 200 K  | train\n",
      "3 | fcvar      | Linear    | 5.1 K  | train\n",
      "4 | fc3        | Linear    | 5.4 K  | train\n",
      "5 | fc4        | Linear    | 201 K  | train\n",
      "6 | activation | LeakyReLU | 0      | train\n",
      "-------------------------------------------------\n",
      "619 K     Trainable params\n",
      "0         Non-trainable params\n",
      "619 K     Total params\n",
      "2.476     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e31be9facc433b976cab68afc0e2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"vae_compare\")\n",
    "\n",
    "# Load the trained model\n",
    "model = VAE.load_from_checkpoint(\"checkpoints/epoch=29-step=28140.ckpt\")  # Replace with your checkpoint path\n",
    "model.eval()\n",
    "for batch in testloader:\n",
    "    x, _ = batch\n",
    "    x_hat = model(x)\n",
    "\n",
    "    # Reshape to image format\n",
    "    x_hat = x_hat.view(-1, 1, 28, 28)\n",
    "\n",
    "    # Log the images\n",
    "    grid_original = vutils.make_grid(x, normalize=True, scale_each=True)\n",
    "    grid_reconstructed = vutils.make_grid(x_hat, normalize=True, scale_each=True)\n",
    "    logger.experiment.add_image('Original Images', grid_original, 0)\n",
    "    logger.experiment.add_image('Reconstructed Images', grid_reconstructed, 0)\n",
    "\n",
    "    break  # Only log the first batch for demonstration purposes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
